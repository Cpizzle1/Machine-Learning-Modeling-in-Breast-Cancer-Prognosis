{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn.model_selection import GridSearchCV, RandomizedSearchCV\n",
    "from sklearn.metrics import mean_squared_error, r2_score, make_scorer, roc_auc_score, roc_curve, auc\n",
    "import matplotlib.pyplot as plt\n",
    "plt.style.use('ggplot')\n",
    "import numpy as np\n",
    "import pandas as pd "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.linear_model import LogisticRegression,LogisticRegressionCV,SGDClassifier, Lasso\n",
    "from sklearn.model_selection import RandomizedSearchCV,GridSearchCV\n",
    "from sklearn.ensemble import GradientBoostingRegressor, RandomForestClassifier,GradientBoostingClassifier,AdaBoostClassifier\n",
    "from sklearn.model_selection import KFold, train_test_split\n",
    "from sklearn.metrics import r2_score, median_absolute_error, mean_absolute_error, accuracy_score, f1_score,accuracy_score\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "from sklearn import svm\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score\n",
    "import pickle\n",
    "\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.utils import shuffle\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "from sklearn.decomposition import PCA\n",
    "from mpl_toolkits.mplot3d import Axes3D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/cp/opt/anaconda3/lib/python3.7/site-packages/IPython/core/interactiveshell.py:3147: DtypeWarning: Columns (678,688,690,692) have mixed types.Specify dtype option on import or set low_memory=False.\n",
      "  interactivity=interactivity, compiler=compiler, result=result)\n"
     ]
    }
   ],
   "source": [
    "mrna_df =pd.read_csv('/Users/cp/Documents/dsi/capstone2/capstone2/data/capstone2.mrn_df2.csv')\n",
    "df = pd.read_csv('/Users/cp/Documents/dsi/capstone2/capstone2/data/METABRIC_RNA_Mutation.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "death_from_dict = {\n",
    "    'Living':0\n",
    "    ,'Died of Other Causes':0\n",
    "    ,'Died of Disease':1\n",
    "}\n",
    "df.replace(death_from_dict, inplace =True)\n",
    "mrna_df['death_from_cancer'] = df.death_from_cancer\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "mrna_df.death_from_cancer.fillna(0, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# mrna_df = np.random.shuffle(mrna_df.values)\n",
    "mrna_df = shuffle(mrna_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>brca1</th>\n",
       "      <th>brca2</th>\n",
       "      <th>palb2</th>\n",
       "      <th>pten</th>\n",
       "      <th>tp53</th>\n",
       "      <th>atm</th>\n",
       "      <th>cdh1</th>\n",
       "      <th>chek2</th>\n",
       "      <th>nbn</th>\n",
       "      <th>nf1</th>\n",
       "      <th>...</th>\n",
       "      <th>srd5a2</th>\n",
       "      <th>srd5a3</th>\n",
       "      <th>st7</th>\n",
       "      <th>star</th>\n",
       "      <th>tnk2</th>\n",
       "      <th>tulp4</th>\n",
       "      <th>ugt2b15</th>\n",
       "      <th>ugt2b17</th>\n",
       "      <th>ugt2b7</th>\n",
       "      <th>death_from_cancer</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1235</th>\n",
       "      <td>3.4308</td>\n",
       "      <td>-0.3739</td>\n",
       "      <td>0.6722</td>\n",
       "      <td>-0.3025</td>\n",
       "      <td>-1.5030</td>\n",
       "      <td>-0.2648</td>\n",
       "      <td>0.2795</td>\n",
       "      <td>-1.0279</td>\n",
       "      <td>0.7436</td>\n",
       "      <td>1.7949</td>\n",
       "      <td>...</td>\n",
       "      <td>0.9403</td>\n",
       "      <td>1.1917</td>\n",
       "      <td>-0.9159</td>\n",
       "      <td>0.4131</td>\n",
       "      <td>-0.8903</td>\n",
       "      <td>-0.4268</td>\n",
       "      <td>-0.1262</td>\n",
       "      <td>-0.6897</td>\n",
       "      <td>1.1016</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>0.9407</td>\n",
       "      <td>1.9690</td>\n",
       "      <td>-0.6174</td>\n",
       "      <td>1.8832</td>\n",
       "      <td>0.5866</td>\n",
       "      <td>-0.9574</td>\n",
       "      <td>-1.2465</td>\n",
       "      <td>-0.1306</td>\n",
       "      <td>0.6905</td>\n",
       "      <td>-0.1343</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.0474</td>\n",
       "      <td>2.0770</td>\n",
       "      <td>1.0822</td>\n",
       "      <td>-0.3488</td>\n",
       "      <td>-2.6232</td>\n",
       "      <td>0.0989</td>\n",
       "      <td>-0.8832</td>\n",
       "      <td>-1.0515</td>\n",
       "      <td>-0.8522</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1044</th>\n",
       "      <td>0.2056</td>\n",
       "      <td>0.2372</td>\n",
       "      <td>-0.9531</td>\n",
       "      <td>0.5284</td>\n",
       "      <td>1.8582</td>\n",
       "      <td>-0.7047</td>\n",
       "      <td>-2.7716</td>\n",
       "      <td>0.7935</td>\n",
       "      <td>-0.6156</td>\n",
       "      <td>0.6985</td>\n",
       "      <td>...</td>\n",
       "      <td>0.6403</td>\n",
       "      <td>0.6190</td>\n",
       "      <td>2.1305</td>\n",
       "      <td>0.5177</td>\n",
       "      <td>-0.2285</td>\n",
       "      <td>0.3405</td>\n",
       "      <td>-0.3355</td>\n",
       "      <td>-0.6103</td>\n",
       "      <td>0.2185</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>985</th>\n",
       "      <td>-0.5325</td>\n",
       "      <td>-0.7138</td>\n",
       "      <td>-0.2146</td>\n",
       "      <td>1.0154</td>\n",
       "      <td>-0.2258</td>\n",
       "      <td>0.7800</td>\n",
       "      <td>-0.1565</td>\n",
       "      <td>-0.6821</td>\n",
       "      <td>0.6847</td>\n",
       "      <td>0.2644</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.0164</td>\n",
       "      <td>0.6475</td>\n",
       "      <td>-0.4848</td>\n",
       "      <td>-1.5410</td>\n",
       "      <td>0.0701</td>\n",
       "      <td>0.3893</td>\n",
       "      <td>0.0087</td>\n",
       "      <td>-0.0493</td>\n",
       "      <td>-0.0245</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>775</th>\n",
       "      <td>-0.0557</td>\n",
       "      <td>0.5698</td>\n",
       "      <td>0.0612</td>\n",
       "      <td>-0.4954</td>\n",
       "      <td>-0.8684</td>\n",
       "      <td>-0.1263</td>\n",
       "      <td>-1.3515</td>\n",
       "      <td>-0.9544</td>\n",
       "      <td>0.7861</td>\n",
       "      <td>-1.2817</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.9926</td>\n",
       "      <td>0.5069</td>\n",
       "      <td>-0.6232</td>\n",
       "      <td>-0.0605</td>\n",
       "      <td>0.0080</td>\n",
       "      <td>0.8955</td>\n",
       "      <td>-0.5276</td>\n",
       "      <td>-1.3380</td>\n",
       "      <td>-0.2690</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>639</th>\n",
       "      <td>-1.2013</td>\n",
       "      <td>0.3274</td>\n",
       "      <td>0.2283</td>\n",
       "      <td>1.4324</td>\n",
       "      <td>-0.5455</td>\n",
       "      <td>-0.6773</td>\n",
       "      <td>-0.2210</td>\n",
       "      <td>-0.5705</td>\n",
       "      <td>0.1355</td>\n",
       "      <td>-0.1422</td>\n",
       "      <td>...</td>\n",
       "      <td>1.1908</td>\n",
       "      <td>-0.1471</td>\n",
       "      <td>-0.6174</td>\n",
       "      <td>-0.4737</td>\n",
       "      <td>-0.8231</td>\n",
       "      <td>0.1655</td>\n",
       "      <td>-0.1718</td>\n",
       "      <td>-0.5390</td>\n",
       "      <td>-0.4916</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1606</th>\n",
       "      <td>0.4316</td>\n",
       "      <td>0.5906</td>\n",
       "      <td>0.6499</td>\n",
       "      <td>0.6992</td>\n",
       "      <td>-0.6099</td>\n",
       "      <td>1.3034</td>\n",
       "      <td>-0.1252</td>\n",
       "      <td>-0.4880</td>\n",
       "      <td>1.8516</td>\n",
       "      <td>1.9536</td>\n",
       "      <td>...</td>\n",
       "      <td>0.5877</td>\n",
       "      <td>-0.6983</td>\n",
       "      <td>0.7891</td>\n",
       "      <td>-0.5926</td>\n",
       "      <td>0.5263</td>\n",
       "      <td>0.5195</td>\n",
       "      <td>-0.7514</td>\n",
       "      <td>-1.2846</td>\n",
       "      <td>-0.3763</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>711</th>\n",
       "      <td>0.4405</td>\n",
       "      <td>-0.3679</td>\n",
       "      <td>-1.1658</td>\n",
       "      <td>-0.5324</td>\n",
       "      <td>-0.1581</td>\n",
       "      <td>0.8400</td>\n",
       "      <td>1.0522</td>\n",
       "      <td>-0.1539</td>\n",
       "      <td>-0.9428</td>\n",
       "      <td>0.3777</td>\n",
       "      <td>...</td>\n",
       "      <td>0.8002</td>\n",
       "      <td>0.8992</td>\n",
       "      <td>2.0359</td>\n",
       "      <td>0.2968</td>\n",
       "      <td>0.3446</td>\n",
       "      <td>3.4423</td>\n",
       "      <td>-0.8026</td>\n",
       "      <td>0.0751</td>\n",
       "      <td>-0.9454</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1092</th>\n",
       "      <td>-0.4988</td>\n",
       "      <td>-2.4081</td>\n",
       "      <td>-0.1584</td>\n",
       "      <td>0.3926</td>\n",
       "      <td>-0.3083</td>\n",
       "      <td>0.3457</td>\n",
       "      <td>-0.5430</td>\n",
       "      <td>-1.5103</td>\n",
       "      <td>-0.1946</td>\n",
       "      <td>0.3205</td>\n",
       "      <td>...</td>\n",
       "      <td>0.2527</td>\n",
       "      <td>-1.2086</td>\n",
       "      <td>0.3094</td>\n",
       "      <td>0.7085</td>\n",
       "      <td>1.1191</td>\n",
       "      <td>-0.5850</td>\n",
       "      <td>-0.1910</td>\n",
       "      <td>0.8158</td>\n",
       "      <td>1.6913</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>146</th>\n",
       "      <td>-1.1954</td>\n",
       "      <td>-0.7210</td>\n",
       "      <td>0.9600</td>\n",
       "      <td>1.3898</td>\n",
       "      <td>1.5699</td>\n",
       "      <td>-0.5194</td>\n",
       "      <td>0.2603</td>\n",
       "      <td>0.8901</td>\n",
       "      <td>1.1422</td>\n",
       "      <td>0.4454</td>\n",
       "      <td>...</td>\n",
       "      <td>0.9863</td>\n",
       "      <td>0.9638</td>\n",
       "      <td>0.2892</td>\n",
       "      <td>0.9431</td>\n",
       "      <td>-0.6316</td>\n",
       "      <td>-0.0895</td>\n",
       "      <td>-0.2584</td>\n",
       "      <td>0.1596</td>\n",
       "      <td>-0.8188</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1904 rows Ã— 490 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       brca1   brca2   palb2    pten    tp53     atm    cdh1   chek2     nbn  \\\n",
       "1235  3.4308 -0.3739  0.6722 -0.3025 -1.5030 -0.2648  0.2795 -1.0279  0.7436   \n",
       "21    0.9407  1.9690 -0.6174  1.8832  0.5866 -0.9574 -1.2465 -0.1306  0.6905   \n",
       "1044  0.2056  0.2372 -0.9531  0.5284  1.8582 -0.7047 -2.7716  0.7935 -0.6156   \n",
       "985  -0.5325 -0.7138 -0.2146  1.0154 -0.2258  0.7800 -0.1565 -0.6821  0.6847   \n",
       "775  -0.0557  0.5698  0.0612 -0.4954 -0.8684 -0.1263 -1.3515 -0.9544  0.7861   \n",
       "...      ...     ...     ...     ...     ...     ...     ...     ...     ...   \n",
       "639  -1.2013  0.3274  0.2283  1.4324 -0.5455 -0.6773 -0.2210 -0.5705  0.1355   \n",
       "1606  0.4316  0.5906  0.6499  0.6992 -0.6099  1.3034 -0.1252 -0.4880  1.8516   \n",
       "711   0.4405 -0.3679 -1.1658 -0.5324 -0.1581  0.8400  1.0522 -0.1539 -0.9428   \n",
       "1092 -0.4988 -2.4081 -0.1584  0.3926 -0.3083  0.3457 -0.5430 -1.5103 -0.1946   \n",
       "146  -1.1954 -0.7210  0.9600  1.3898  1.5699 -0.5194  0.2603  0.8901  1.1422   \n",
       "\n",
       "         nf1  ...  srd5a2  srd5a3     st7    star    tnk2   tulp4  ugt2b15  \\\n",
       "1235  1.7949  ...  0.9403  1.1917 -0.9159  0.4131 -0.8903 -0.4268  -0.1262   \n",
       "21   -0.1343  ... -0.0474  2.0770  1.0822 -0.3488 -2.6232  0.0989  -0.8832   \n",
       "1044  0.6985  ...  0.6403  0.6190  2.1305  0.5177 -0.2285  0.3405  -0.3355   \n",
       "985   0.2644  ... -1.0164  0.6475 -0.4848 -1.5410  0.0701  0.3893   0.0087   \n",
       "775  -1.2817  ... -0.9926  0.5069 -0.6232 -0.0605  0.0080  0.8955  -0.5276   \n",
       "...      ...  ...     ...     ...     ...     ...     ...     ...      ...   \n",
       "639  -0.1422  ...  1.1908 -0.1471 -0.6174 -0.4737 -0.8231  0.1655  -0.1718   \n",
       "1606  1.9536  ...  0.5877 -0.6983  0.7891 -0.5926  0.5263  0.5195  -0.7514   \n",
       "711   0.3777  ...  0.8002  0.8992  2.0359  0.2968  0.3446  3.4423  -0.8026   \n",
       "1092  0.3205  ...  0.2527 -1.2086  0.3094  0.7085  1.1191 -0.5850  -0.1910   \n",
       "146   0.4454  ...  0.9863  0.9638  0.2892  0.9431 -0.6316 -0.0895  -0.2584   \n",
       "\n",
       "      ugt2b17  ugt2b7  death_from_cancer  \n",
       "1235  -0.6897  1.1016                1.0  \n",
       "21    -1.0515 -0.8522                0.0  \n",
       "1044  -0.6103  0.2185                1.0  \n",
       "985   -0.0493 -0.0245                0.0  \n",
       "775   -1.3380 -0.2690                0.0  \n",
       "...       ...     ...                ...  \n",
       "639   -0.5390 -0.4916                1.0  \n",
       "1606  -1.2846 -0.3763                0.0  \n",
       "711    0.0751 -0.9454                0.0  \n",
       "1092   0.8158  1.6913                0.0  \n",
       "146    0.1596 -0.8188                0.0  \n",
       "\n",
       "[1904 rows x 490 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mrna_df "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "Validation_set = mrna_df[:200]\n",
    "mrna1 = mrna_df[200:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1704"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(Validation_set)\n",
    "len(mrna1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Validation_set.to_csv(r'../data/validation_set.csv', index = False)\n",
    "len"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "y = mrna1.pop('death_from_cancer')\n",
    "X = mrna1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.15, random_state=1, stratify = y)\n",
    "# X_train2, X_test, y_train2, y_test = train_test_split(X_train.copy(), y_train.copy(), test_size=0.10, random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "gradient_boosting_grid = {'learning_rate': [0.1, 0.2, 0.3, 0.4, 0.5]\n",
    "                         ,'max_depth': [2, 4, 8]\n",
    "                         ,'subsample': [0.25, 0.5, 0.75, 1.0]\n",
    "                         ,'min_samples_leaf': [1, 2, 4]\n",
    "                         ,'max_features': ['sqrt', 'log2', None]\n",
    "                         ,'n_estimators': [5,10,25,50,100,200]}\n",
    "\n",
    "random_forest_grid = {'max_depth': [2, 4, 8]\n",
    "                     ,'max_features': ['sqrt', 'log2', None]\n",
    "                     ,'min_samples_leaf': [1, 2, 4]\n",
    "                     ,'min_samples_split': [2, 4]\n",
    "                     ,'bootstrap': [True, False]\n",
    "                     ,'class_weight': ['balanced']\n",
    "\n",
    "                     ,'n_estimators': [5,10,25,50,100,200]}\n",
    "\n",
    "logistic_regression_grid = {'Cs':[2,5,10, 25, 100, 200]\n",
    "                       ,'cv':[4]\n",
    "                       ,'solver':['liblinear']#'lbfgs',\n",
    "                       ,'max_iter' : [50]\n",
    "                       ,'class_weight':['balanced']\n",
    "                       ,'penalty':['l1'] #, 'l2', 'elasticnet'\n",
    "                           }\n",
    "    \n",
    "svm_grid = {'C':[0.5, 1, 2]\n",
    "\n",
    "                       ,'kernel':['rbf', 'liblinear']}\n",
    "\n",
    "ada_grid = {'base_estimator': [DecisionTreeClassifier(class_weight='balanced')], \\\n",
    "                  'n_estimators': [100, 250], \\\n",
    "                  'learning_rate': [0.1, 0.25]}\n",
    "\n",
    "\n",
    "sgd_grid = {'loss': ['hinge', 'log', 'modified_huber'], \\\n",
    "                      'alpha': [0.001, 0.01], \\\n",
    "                      'penalty': ['l1'], \\\n",
    "                      'max_iter': [5, 10, 25], \\\n",
    "                      'class_weight': ['balanced']}\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "logistic_randomsearch = RandomizedSearchCV(LogisticRegressionCV()\n",
    "                                              ,logistic_regression_grid\n",
    "                                              ,n_jobs=-1\n",
    "                                              ,verbose=False\n",
    "                                              ,scoring='roc_auc')\n",
    "\n",
    "svm_randomsearch = RandomizedSearchCV(SVC(gamma = 'auto')\n",
    "                                              ,svm_grid\n",
    "                                              ,n_jobs=-1\n",
    "                                              ,verbose=False\n",
    "                                              ,scoring='roc_auc')\n",
    "\n",
    "gradient_randomsearch = RandomizedSearchCV(GradientBoostingClassifier()\n",
    "                                          ,gradient_boosting_grid\n",
    "                                          ,n_jobs=-1\n",
    "                                          ,verbose=False\n",
    "                                          ,scoring='roc_auc')\n",
    "\n",
    "random_foreset_randomsearch = RandomizedSearchCV(RandomForestClassifier()\n",
    "                                                ,random_forest_grid\n",
    "                                                ,n_jobs=-1\n",
    "                                                ,verbose=False\n",
    "                                                ,scoring='roc_auc')\n",
    "\n",
    "ada_randomsearch = RandomizedSearchCV(AdaBoostClassifier()\n",
    "                                                ,ada_grid\n",
    "                                                ,n_jobs=-1\n",
    "                                                ,verbose=False\n",
    "                                                ,scoring='roc_auc')\n",
    "\n",
    "SGD_randomsearch = RandomizedSearchCV(SGDClassifier()\n",
    "                                                ,sgd_grid\n",
    "                                                ,n_jobs=-1\n",
    "                                                ,verbose=False\n",
    "                                                ,scoring='roc_auc')\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/cp/opt/anaconda3/lib/python3.7/site-packages/sklearn/model_selection/_search.py:282: UserWarning: The total space of parameters 6 is smaller than n_iter=10. Running 6 iterations. For exhaustive searches, use GridSearchCV.\n",
      "  % (grid_size, self.n_iter, grid_size), UserWarning)\n"
     ]
    }
   ],
   "source": [
    "logistic_randomsearch.fit(X_train, y_train)\n",
    "print(f\"Best logistic Parameters: {logistic_randomsearch.best_params_}\")\n",
    "print(f\"Best logistic Model: {logistic_randomsearch.best_estimator_}\")\n",
    "print(f\"Best logistic Score: {logistic_randomsearch.best_score_:.4f}\")\n",
    "\n",
    "svm_randomsearch.fit(X_train, y_train)\n",
    "print(f\"Best svm Parameters: {svm_randomsearch.best_params_}\")\n",
    "print(f\"Best svm Model: {svm_randomsearch.best_estimator_}\")\n",
    "print(f\"Best svm Score: {svm_randomsearch.best_score_:.4f}\")\n",
    "\n",
    "gradient_randomsearch.fit(X_train, y_train)\n",
    "print(f\"Best Gradient Parameters: {gradient_randomsearch.best_params_}\")\n",
    "print(f\"Best Gradient Model: {gradient_randomsearch.best_estimator_}\")\n",
    "print(f\"Best Gradient Score: {gradient_randomsearch.best_score_:.4f}\")\n",
    "\n",
    "random_foreset_randomsearch.fit(X_train, y_train)\n",
    "print(f\"Best Random Forest Parameters: {random_foreset_randomsearch.best_params_}\")\n",
    "print(f\"Best Random Forest Model: {random_foreset_randomsearch.best_estimator_}\")\n",
    "print(f\"Best Random Forest Score: {random_foreset_randomsearch.best_score_:.4f}\")\n",
    "\n",
    "\n",
    "ada_randomsearch.fit(X_train, y_train)\n",
    "print(f\"Best Random adaboost Parameters: {ada_randomsearch.best_params_}\")\n",
    "print(f\"Best Random adaboost Model: {ada_randomsearch.best_estimator_}\")\n",
    "print(f\"Best Random adaboost Score: {ada_randomsearch.best_score_:.4f}\")\n",
    "\n",
    "SGD_randomsearch.fit(X_train, y_train)\n",
    "print(f\"Best Random SGD Parameters: {SGD_randomsearch.best_params_}\")\n",
    "print(f\"Best Random SGD Model: {SGD_randomsearch.best_estimator_}\")\n",
    "print(f\"Best Random SGD Score: {SGD_randomsearch.best_score_:.4f}\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logistic_best_model = logistic_randomsearch.best_estimator_\n",
    "logistic_y_hats = logistic_best_model.predict(X_test)\n",
    "print(f\"Gradient ROC Score = {roc_auc_score(y_test, logistic_y_hats):.4f}\")\n",
    "\n",
    "svm_best_model = svm_randomsearch.best_estimator_\n",
    "svm_y_hats = svm_best_model.predict(X_test)\n",
    "print(f\"SVM ROC Score = {roc_auc_score(y_test, svm_y_hats):.4f}\")\n",
    "\n",
    "gradient_best_model = gradient_randomsearch.best_estimator_\n",
    "gy_hats = gradient_best_model.predict(X_test)\n",
    "print(f\"Gradient ROC Score = {roc_auc_score(y_test, gy_hats):.4f}\")\n",
    "\n",
    "random_forest_best_model = random_foreset_randomsearch.best_estimator_\n",
    "ry_hats = random_forest_best_model.predict(X_test)\n",
    "print(f\"Random Forest ROC Score = {roc_auc_score(y_test, ry_hats):.4f}\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "ada_boost_best_model = ada_randomsearch.best_estimator_\n",
    "ada_y_hats = ada_boost_best_model.predict(X_test)\n",
    "print(f\"Random Adaboost ROC Score = {roc_auc_score(y_test, ada_y_hats):.4f}\")\n",
    "\n",
    "SGD_best_model = SGD_randomsearch.best_estimator_\n",
    "SGD_y_hats = SGD_best_model.predict(X_test)\n",
    "print(f\"Random SGD ROC Score = {roc_auc_score(y_test, SGD_y_hats):.4f}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# lst =X_train.shape,X_train2.shape, X_test.shape, X_val.shape\n",
    "# print(lst)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classification_report(y_test, logistic_y_hats))\n",
    "\n",
    "print(classification_report(y_test, svm_y_hats))\n",
    "print(classification_report(y_test, gy_hats))\n",
    "print(classification_report(y_test, ry_hats))\n",
    "print(classification_report(y_test, ada_y_hats))\n",
    "print(classification_report(y_test, SGD_y_hats))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(accuracy_score(y_test, logistic_y_hats))\n",
    "\n",
    "print(accuracy_score(y_test, svm_y_hats))\n",
    "print(accuracy_score(y_test, gy_hats))\n",
    "print(accuracy_score(y_test, ry_hats))\n",
    "print(accuracy_score(y_test, ada_y_hats))\n",
    "print(accuracy_score(y_test, SGD_y_hats))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plotting ROC Curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def roc_curve_grapher(model, X_test ,y_test):\n",
    "    \"\"\"[Makes ROC curve graph given model and data]\n",
    "    Args:\n",
    "        model ([SKlearn classifer model]): [Logistic regression, Random Forrest, Gradient Boosting, etc]]\n",
    "        X_test ([Pandas dataframe]): [Test feature data]\n",
    "        y_test ([numpy array]): [target valudation data]\n",
    "    \"\"\"\n",
    "\n",
    "    yhat = model.predict_proba(X_test)\n",
    "    yhat = yhat[:, 1]\n",
    "    fpr, tpr, thresholds = roc_curve(y_test, yhat)\n",
    "    plt.plot([0,1], [0,1], linestyle='--', label='Random guess')\n",
    "    plt.plot(fpr, tpr, marker='.', label=f'Model')\n",
    "    plt.xlabel('False Positive Rate')\n",
    "    plt.ylabel('True Positive Rate')\n",
    "    plt.suptitle('Model ROC curve', fontsize=20)\n",
    "    plt.legend()\n",
    "    plt.savefig(\"Logistic Regression_ROC_curve.png\", dpi=200)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "random_forest_best_model.fit(X_train, y_train)\n",
    "# predict probabilities\n",
    "yhat = random_forest_best_model.predict_proba(X_test)\n",
    "# keep probabilities for the positive outcome only\n",
    "yhat = yhat[:, 1]\n",
    "# calculate roc curves\n",
    "fpr, tpr, thresholds = roc_curve(y_test, yhat)\n",
    "# plot the roc curve for the model\n",
    "plt.plot([0,1], [0,1], linestyle='--', label='Random guess')\n",
    "plt.plot(fpr, tpr, marker='.', label='Random Forrest')\n",
    "# axis labels\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.legend()\n",
    "# show the plot\n",
    "plt.savefig(\"Random_Forrest_ROC_curve.png\", dpi=200)\n",
    "plt.show()\n",
    "\n",
    "\n",
    "\n",
    "from sklearn import metrics\n",
    "# preds =logistic_best_model.predict_proba(X_test)\n",
    "# tpr, tpr, thresholds = metrics.roc_curve(y_test,preds[:,1])\n",
    "# print (thresholds)\n",
    "\n",
    "# accuracy_ls = []\n",
    "# for thres in thresholds:\n",
    "#     y_pred = np.where(preds[:,1]>thres,1,0)\n",
    "#     # Apply desired utility function to y_preds, for example accuracy.\n",
    "#     accuracy_ls.append(metrics.recall_score(y_test, y_pred))\n",
    "# accuracy_ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# validate_lg_y_hat = logistic_best_model.predict(X_val)\n",
    "# validate_svm_y_hat = svm_best_model.predict(X_val)\n",
    "# validate_gb_y_hat = gradient_best_model.predict(X_val)\n",
    "# validate_rf_y_hat = random_forest_best_model.predict(X_val)\n",
    "validate_ada_y_hat = ada_boost_best_model.predict(X_val)\n",
    "validate_SGD_y_hat = SGD_best_model.predict(X_val)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(accuracy_score(y_val, validate_lg_y_hat))\n",
    "# print(accuracy_score(y_val, validate_svm_y_hat))\n",
    "# print(accuracy_score(y_val, validate_gb_y_hat))\n",
    "# print(accuracy_score(y_val, validate_rf_y_hat))\n",
    "print(accuracy_score(y_val, validate_ada_y_hat))\n",
    "print(accuracy_score(y_val, validate_SGD_y_hat))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# print(classification_report(y_val, validate_lg_y_hat))\n",
    "# print(classification_report(y_val, validate_svm_y_hat))\n",
    "# print(classification_report(y_val, validate_gb_y_hat))\n",
    "# print(classification_report(y_val, validate_rf_y_hat))\n",
    "print(classification_report(y_val, validate_ada_y_hat))\n",
    "print(classification_report(y_val, validate_SGD_y_hat))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# filename = 'random_forrest_model1.sav'\n",
    "# pickle.dump(random_forest_best_model, open(filename, 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# filename = 'gradient_best_model1.sav'\n",
    "# pickle.dump(gradient_best_model, open(filename, 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# filename = 'svm_best_model1.sav'\n",
    "# pickle.dump(svm_best_model, open(filename, 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# filename = 'logistic_best_model1.sav'\n",
    "# pickle.dump(logistic_best_model, open(filename, 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pca = PCA(n_components = 0.9)\n",
    "X_train_pca = pca.fit_transform(X_train)\n",
    "X_test_pca = pca.transform(X_test)\n",
    "print(X_train_pca.shape)\n",
    "print(X_test_pca.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "total = sum(pca.explained_variance_)\n",
    "k = 0\n",
    "current_variance = 0\n",
    "while current_variance/total < 0.90:\n",
    "    current_variance += pca.explained_variance_[k]\n",
    "    k = k + 1\n",
    "    \n",
    "print(k, \" features explain around 75% of the variance. From 489 features to \", k, \", not too bad.\", sep='')\n",
    "\n",
    "pca = PCA(n_components=k)\n",
    "X_train.pca = pca.fit(X_train)\n",
    "X_train_pca = pca.transform(X_train)\n",
    "X_test_pca = pca.transform(X_test)\n",
    "\n",
    "var_exp = pca.explained_variance_ratio_.cumsum()\n",
    "var_exp = var_exp*100\n",
    "plt.bar(range(k), var_exp)\n",
    "plt.xlabel(\"Number of components\", fontsize = 13)\n",
    "plt.ylabel(\"Percent of Variance Explained\", fontsize = 13)\n",
    "# fig.suptitle('test title', fontsize=20)\n",
    "\n",
    "plt.title(\"Variance explained by principle components\", fontsize=18)\n",
    "# plt.set_ylabel('Patient Count');\n",
    "# plt.savefig(\"PCA_component_variance.png\", dpi=200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pca3 = PCA(n_components = 3).fit_transform(X_train)\n",
    "colors = np.where(y_train==0, 'red', 'blue')\n",
    "plt.clf()\n",
    "fig = plt.figure(1, figsize=(10,6 ))\n",
    "ax = Axes3D(fig, elev=-150, azim=110,)\n",
    "ax.scatter(pca3[:, 0], pca3[:, 1], pca3[:, 2], c=colors, cmap=plt.cm.Paired,linewidths=10)\n",
    "ax.set_title(\"First three PCA dimensions\")\n",
    "ax.set_xlabel(\"PC1\")\n",
    "ax.w_xaxis.set_ticklabels([])\n",
    "ax.set_ylabel(\"PC2\")\n",
    "ax.w_yaxis.set_ticklabels([])\n",
    "ax.set_zlabel(\"PC3\")\n",
    "ax.w_zaxis.set_ticklabels([])\n",
    "# plt.savefig(\"PCA_first_3_plt.png\", dpi=200)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logistic_regression_grid2 = {'Cs':[2, 5]\n",
    "                       ,'cv':[2,4,8]\n",
    "                       ,'solver':['lbfgs', 'liblinear']\n",
    "                       ,'max_iter' : [50]\n",
    "                       ,'penalty':['l1', 'l2', 'elasticnet']\n",
    "                           }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logistic_randomsearch2 = RandomizedSearchCV(LogisticRegressionCV()\n",
    "                                              ,logistic_regression_grid2\n",
    "                                              ,n_jobs=-1\n",
    "                                              ,verbose=False\n",
    "                                              ,scoring='roc_auc')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# logRegRidge = LogisticRegressionCV(penalty='l2', max_iter=100)\n",
    "# logRegRidge.fit(X_train2, y_train2)\n",
    "# print(f'Ridge Coefficients:{logRegRidge.coef_}')\n",
    "    \n",
    "# logReg_pred_p = logRegRidge.predict_proba(X_test)\n",
    "# y_pred = logRegRidge.predict(X_test)\n",
    "    \n",
    "# Lasso\n",
    "\n",
    "log_Reg_Lasso = LogisticRegressionCV(max_iter=200)\n",
    "log_Reg_Lasso.fit(X_train, y_train)\n",
    "print(f'Lasso Coefficients:{log_Reg_Lasso.coef_}')\n",
    "    \n",
    "log_Reg_Lasso_pred_p = log_Reg_Lasso.predict_proba(X_test)\n",
    "y_pred = log_Reg_Lasso.predict(X_test) \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# logistic_randomsearch2.fit(X_train2, y_train2)\n",
    "# print(f\"Best logistic Parameters: {logistic_randomsearch2.best_params_}\")\n",
    "# print(f\"Best logistic Model: {logistic_randomsearch2.best_estimator_}\")\n",
    "# print(f\"Best logistic Score: {logistic_randomsearch2.best_score_:.4f}\")\n",
    "\n",
    "\n",
    "# # logRegRidge = LogisticRegressionCV(penalty='l2', max_iter=200)\n",
    "# # logRegRidge.fit(X_train, y_train)\n",
    "# print(f'LogisticRegression Coefficients:{logistic_randomsearch2.coef_}')\n",
    "    \n",
    "# logReg_pred_p = logistic_randomsearch2.predict_proba(X_test)\n",
    "# y_pred = logistic_randomsearch2.predict(X_test)\n",
    "#_______________________________________________________________________    \n",
    "# Lasso\n",
    "\n",
    "# log_Reg_Lasso = LogisticRegressionCV(max_iter=200)\n",
    "# log_Reg_Lasso.fit(X_train, y_train)\n",
    "# print(f'Lasso Coefficients:{log_Reg_Lasso.coef_}')\n",
    "    \n",
    "# log_Reg_Lasso_pred_p = log_Reg_Lasso.predict_proba(X_test)\n",
    "# y_pred = log_Reg_Lasso.predict(X_test) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logistic_randomsearch2.fit(X_train, y_train)\n",
    "\n",
    "logistic_best_model2 = logistic_randomsearch2.best_estimator_\n",
    "logistic2_y_hats = logistic_best_model2.predict(X_test)\n",
    "print(f\"Gradient ROC Score = {roc_auc_score(y_test, logistic2_y_hats):.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classification_report(y_test, logistic2_y_hats))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# y.to_csv(r'capstone2/data/target_death_col.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pwd\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "ada_randomsearch.fit(X_train, y_train)\n",
    "print(f\"Best Random adaboost Parameters: {ada_randomsearch.best_params_}\")\n",
    "print(f\"Best Random adaboost Model: {ada_randomsearch.best_estimator_}\")\n",
    "print(f\"Best Random adaboost Score: {ada_randomsearch.best_score_:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loaded_model = pickle.load(open('/Users/cp/Documents/dsi/capstone2/capstone2/models/gradient_best_model1.sav', 'rb'))\n",
    "result = loaded_model.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y2_loaded = loaded_model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classification_report(y_test, y2_loaded))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loaded_model.feature_importances_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "importances = loaded_model.feature_importances_\n",
    "std = np.std([loaded_model.feature_importances_ for tree in random_forest_best_model.estimators_],\n",
    "             axis=0)\n",
    "indices = np.argsort(importances)[::-1]\n",
    "\n",
    "# Print the feature ranking\n",
    "print(\"Feature ranking:\")\n",
    "\n",
    "for f in range(X.shape[1]):\n",
    "    print(\"%d. feature %d (%f)\" % (f + 1, indices[f], importances[indices[f]]))\n",
    "\n",
    "# Plot the impurity-based feature importances of the forest\n",
    "plt.figure()\n",
    "plt.title(\"Feature importances\")\n",
    "plt.bar(range(X_train.shape[1]), importances[indices],\n",
    "        color=\"r\", yerr=std[indices], align=\"center\")\n",
    "plt.xticks(range(X_train.shape[1]), indices)\n",
    "plt.xlim([-1, X_train.shape[1]])\n",
    "plt.xlabel(\"Feature listed in descending importance level\", fontsize = 13)\n",
    "plt.ylabel(\"Importance Value\", fontsize = 13)\n",
    "plt.savefig(\"gradient_boost_feature_importance.png\", dpi=200)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "random_forest_best_model\n",
    "\n",
    "importances = random_forest_best_model.feature_importances_\n",
    "std = np.std([tree.feature_importances_ for tree in random_forest_best_model.estimators_],\n",
    "             axis=0)\n",
    "indices = np.argsort(importances)[::-1]\n",
    "\n",
    "# Print the feature ranking\n",
    "print(\"Feature ranking:\")\n",
    "\n",
    "for f in range(X_train.shape[1]):\n",
    "    print(\"%d. feature %d (%f)\" % (f + 1, indices[f], importances[indices[f]]))\n",
    "\n",
    "# Plot the impurity-based feature importances of the forest\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "importances = random_forest_best_model.feature_importances_\n",
    "std = np.std([random_forest_best_model.feature_importances_ for tree in random_forest_best_model.estimators_],\n",
    "             axis=0)\n",
    "indices = np.argsort(importances)[::-1]\n",
    "\n",
    "# Print the feature ranking\n",
    "print(\"Feature ranking:\")\n",
    "\n",
    "for f in range(X.shape[1]):\n",
    "    print(\"%d. feature %d (%f)\" % (f + 1, indices[f], importances[indices[f]]))\n",
    "\n",
    "# Plot the impurity-based feature importances of the forest\n",
    "plt.figure()\n",
    "plt.title(\"Feature importances\")\n",
    "plt.bar(range(X_train.shape[1]), importances[indices],\n",
    "        color=\"r\", yerr=std[indices], align=\"center\")\n",
    "plt.xticks(range(X_train.shape[1]), indices)\n",
    "plt.xlim([-1, X_train.shape[1]])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize = (16, 8))\n",
    "plt.title(\"Feature importances\", fontsize = 18)\n",
    "\n",
    "plt.bar(range(X_train.shape[1]), importances[indices],\n",
    "        color=\"r\", yerr=std[indices], align=\"center\")\n",
    "plt.xticks(range(X_train.shape[1]), indices)\n",
    "plt.xlim([-1, X_train.shape[1]])\n",
    "plt.xlabel(\"Feature listed in descending importance level\", fontsize = 13)\n",
    "plt.ylabel(\"Importance Value\", fontsize = 13)\n",
    "plt.savefig(\"random_forest_feature_importance.png\", dpi=200)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test.iloc[:,120]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
